{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4149f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-04 12:22:45.571442: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-06-04 12:22:45.571467: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow_text as text\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a28a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "SHARD_SIZE = 5000 # number of batches\n",
    "HYPOTHETICAL_BATCH_SIZE = 32\n",
    "EXPORT_DIR = 'export/persentence_ds_shard/'\n",
    "\n",
    "take_size = SHARD_SIZE * HYPOTHETICAL_BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7223e280",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(EXPORT_DIR)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "750b77c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-04 12:22:47.167185: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-06-04 12:22:47.167212: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-06-04 12:22:47.167235: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (mingkaichen-Macmini): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "with open('export/berte_tokenizer.model', 'rb') as f:\n",
    "    tokenizer = text.SentencepieceTokenizer(model=f.read(), out_type=tf.int32, add_bos=True, add_eos=True)\n",
    "vocab_size = tokenizer.vocab_size().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66daa3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_batches = tf.data.experimental.load('export/persentence_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84c9b4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen():\n",
    "    for inst in all_batches:\n",
    "        yield inst, tokenizer.tokenize(inst).shape[0]\n",
    "\n",
    "training_set = (tf.data.Dataset.from_generator(gen, output_signature=(\n",
    "                                                    tf.TensorSpec(shape=(), dtype=tf.string),\n",
    "                                                    tf.TensorSpec(shape=(), dtype=tf.int32),\n",
    "                                                ))\n",
    "                                .cache()\n",
    "                                .shuffle(BUFFER_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00f0ed2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=4306689, full_takes=26, part_take=146689\n"
     ]
    }
   ],
   "source": [
    "n = all_batches.cardinality()\n",
    "full_takes = int(n / take_size)\n",
    "part_take = n % take_size\n",
    "print(f'n={n}, full_takes={full_takes}, part_take={part_take}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4de406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-04 12:22:57.294264: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 10109 of 20000\n",
      "2023-06-04 12:23:07.293871: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 19778 of 20000\n",
      "2023-06-04 12:23:07.598154: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n",
      "2023-06-04 12:25:59.499843: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-06-04 12:26:09.620581: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 14294 of 20000\n",
      "2023-06-04 12:26:17.092271: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n",
      "2023-06-04 12:28:54.167850: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-06-04 12:29:04.309176: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 9073 of 20000\n",
      "2023-06-04 12:29:14.310273: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 19896 of 20000\n",
      "2023-06-04 12:29:14.455934: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n",
      "2023-06-04 12:32:03.272047: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-06-04 12:32:13.433422: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 9328 of 20000\n",
      "2023-06-04 12:32:23.432148: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 17565 of 20000\n",
      "2023-06-04 12:32:25.089059: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n",
      "2023-06-04 12:35:11.371400: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-06-04 12:35:21.505573: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 14481 of 20000\n",
      "2023-06-04 12:35:29.148568: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n"
     ]
    }
   ],
   "source": [
    "for i in range(full_takes):\n",
    "    model = EXPORT_DIR + f'fshard_{i}'\n",
    "    tf.data.experimental.save(training_set.take(take_size), model)\n",
    "\n",
    "tf.data.experimental.save(training_set.take(part_take), EXPORT_DIR + 'pshard')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
